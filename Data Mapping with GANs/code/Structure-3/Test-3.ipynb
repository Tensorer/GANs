{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v1CUZ0dkOo_F"
   },
   "source": [
    "# Data Mapping with Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1_Y75QXJS6h"
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "tfds.disable_progress_bar()\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iuGVPOo7Cce0"
   },
   "outputs": [],
   "source": [
    "# load map data set\n",
    "dataset, metadata = tfds.load(\n",
    "    'cycle_gan/maps', split=None, data_dir='..\\..\\dataset', batch_size=None, shuffle_files=False,\n",
    "    download=True, as_supervised=True, decoders=None, read_config=None,\n",
    "    with_info=True, builder_kwargs=None, download_and_prepare_kwargs=None,\n",
    "    as_dataset_kwargs=None, try_gcs=False\n",
    ")\n",
    "train_Gps_maps, train_general_maps = dataset['trainA'], dataset['trainB']\n",
    "test_Gps_maps, test_general_maps = dataset['testA'], dataset['testB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (test_Gps_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CbTEt448b4R"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yn3IwqhiIszt"
   },
   "outputs": [],
   "source": [
    "# random crop\n",
    "def random_crop(image):\n",
    "  cropped_image = tf.image.random_crop(\n",
    "      image, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "  return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "muhR2cgbLKWW"
   },
   "outputs": [],
   "source": [
    "# data normalization\n",
    "def normalize(image):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = (image / 127.5) - 1\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVQOjcPVLrUc"
   },
   "outputs": [],
   "source": [
    "# random jitter: resize 288*288*3 + random crop 256*256*3 + random flip\n",
    "def random_jitter(image):\n",
    "  image = tf.image.resize(image, [288, 288],method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "  image = random_crop(image)\n",
    "  image = tf.image.random_flip_left_right(image)\n",
    "  image = tf.image.random_flip_up_down(image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tyaP4hLJ8b4W"
   },
   "outputs": [],
   "source": [
    "# training set data preprocessing: random jitter + data normalization\n",
    "def preprocess_image_train(image, label):\n",
    "  image = random_jitter(image)\n",
    "  image = normalize(image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VB3Z6D_zKSru"
   },
   "outputs": [],
   "source": [
    "# test set data preprocessing: resize 256*256*3 + data normalization\n",
    "def preprocess_image_test(image, label):\n",
    "  image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH],\n",
    "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "  image = normalize(image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RsajGXxd5JkZ"
   },
   "outputs": [],
   "source": [
    "# read training set and test set\n",
    "train_Gps_maps = train_Gps_maps.map(\n",
    "    preprocess_image_train, num_parallel_calls=AUTOTUNE).cache().batch(1)\n",
    "\n",
    "train_general_maps = train_general_maps.map(\n",
    "    preprocess_image_train, num_parallel_calls=AUTOTUNE).cache().batch(1)\n",
    "\n",
    "test_Gps_maps = test_Gps_maps.map(\n",
    "    preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().batch(1)\n",
    "\n",
    "test_general_maps = test_general_maps.map(\n",
    "    preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e3MhJ3zVLPan"
   },
   "outputs": [],
   "source": [
    "# get sample images\n",
    "sample_Gps_map = next(iter(train_Gps_maps.skip(617).take(1)))\n",
    "sample_general_map = next(iter(train_general_maps.skip(66).take(1)))\n",
    "print(sample_general_map.shape)  #check the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4pOYjMk_KfIB"
   },
   "outputs": [],
   "source": [
    "# show sample satellite map image\n",
    "plt.rcParams['figure.dpi'] = 500\n",
    "plt.subplot(121)\n",
    "plt.title('Satellite map')\n",
    "plt.imshow(sample_Gps_map[0] * 0.5 + 0.5)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Satellite map with random jitter')\n",
    "plt.imshow(random_jitter(sample_Gps_map[0]) * 0.5 + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0KJyB9ENLb2y"
   },
   "outputs": [],
   "source": [
    "# show sample general layout map image\n",
    "plt.subplot(121)\n",
    "plt.title('General layout map')\n",
    "plt.imshow(sample_general_map[0] * 0.5 + 0.5)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('General layout map with random jitter')\n",
    "plt.imshow(random_jitter(sample_general_map[0]) * 0.5 + 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hvX8sKsfMaio"
   },
   "source": [
    "## Establish GANs model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential, regularizers\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "def regularized_padded_conv(*args, **kwargs):\n",
    "    return layers.Conv2D(*args, **kwargs, padding='same', use_bias=False,\n",
    "                         kernel_initializer='he_normal',\n",
    "                         kernel_regularizer=regularizers.l2(5e-4))\n",
    "\n",
    "# channel attention mechanism\n",
    "class ChannelAttention(layers.Layer):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "\n",
    "        self.avg_out= layers.GlobalAveragePooling2D()\n",
    "        self.max_out= layers.GlobalMaxPooling2D()\n",
    "\n",
    "        self.fc1 = layers.Dense(in_planes//ratio, kernel_initializer='he_normal',\n",
    "                                kernel_regularizer=regularizers.l2(5e-4),\n",
    "                                activation=tf.nn.relu,\n",
    "                                use_bias=True, bias_initializer='zeros')\n",
    "        self.fc2 = layers.Dense(in_planes, kernel_initializer='he_normal',\n",
    "                                kernel_regularizer=regularizers.l2(5e-4),\n",
    "                                use_bias=True, bias_initializer='zeros')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        avg_out = self.avg_out(inputs)\n",
    "        max_out = self.max_out(inputs)\n",
    "        out = tf.stack([avg_out, max_out], axis=1)  \n",
    "        out = self.fc2(self.fc1(out))\n",
    "        out = tf.reduce_sum(out, axis=1)     \n",
    "        out = tf.nn.sigmoid(out)\n",
    "        out = layers.Reshape((1, 1, out.shape[1]))(out)\n",
    "        return out\n",
    "\n",
    "# spatial attention mechanism\n",
    "class SpatialAttention(layers.Layer):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv1 = regularized_padded_conv(1, kernel_size=kernel_size, strides=1, activation=tf.nn.sigmoid)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        avg_out = tf.reduce_mean(inputs, axis=3)\n",
    "        max_out = tf.reduce_max(inputs, axis=3)\n",
    "        out = tf.stack([avg_out, max_out], axis=3)          \n",
    "        out = self.conv1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance normalization\n",
    "class InstanceNormalization(tf.keras.layers.Layer):\n",
    "  def __init__(self, epsilon=1e-5):\n",
    "    super(InstanceNormalization, self).__init__()\n",
    "    self.epsilon = epsilon\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.scale = self.add_weight(\n",
    "        name='scale',\n",
    "        shape=input_shape[-1:],\n",
    "        initializer=tf.random_normal_initializer(1., 0.02),\n",
    "        trainable=True)\n",
    "\n",
    "    self.offset = self.add_weight(\n",
    "        name='offset',\n",
    "        shape=input_shape[-1:],\n",
    "        initializer='zeros',\n",
    "        trainable=True)\n",
    "\n",
    "  def call(self, x):\n",
    "    mean, variance = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
    "    inv = tf.math.rsqrt(variance + self.epsilon)\n",
    "    normalized = (x - mean) * inv\n",
    "    return self.scale * normalized + self.offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(filters, size, norm_type='batchnorm', apply_norm=True): # number of filters, filter size, normalization type\n",
    "\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "  if apply_norm:\n",
    "    if norm_type.lower() == 'batchnorm':\n",
    "      result.add(tf.keras.layers.BatchNormalization())\n",
    "    elif norm_type.lower() == 'instancenorm':\n",
    "      result.add(InstanceNormalization())\n",
    "\n",
    "  result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "  return result\n",
    "\n",
    "\n",
    "def upsample(filters, size, norm_type='batchnorm', apply_dropout=False): # number of filters, filter size, normalization type, dropout condition \n",
    "\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "      tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                      padding='same',\n",
    "                                      kernel_initializer=initializer,\n",
    "                                      use_bias=False))\n",
    "\n",
    "  if norm_type.lower() == 'batchnorm':\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "  elif norm_type.lower() == 'instancenorm':\n",
    "    result.add(InstanceNormalization())\n",
    "\n",
    "  if apply_dropout:\n",
    "    result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "  return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_generator(output_channels, norm_type='batchnorm'): # output channels, normalization type\n",
    "\n",
    "  down_stack = [\n",
    "      downsample(64, 4, norm_type, apply_norm=False),  # output size: (batch size, 128, 128, 64)\n",
    "      downsample(128, 4, norm_type),  # output size: (batch size, 64, 64, 128)\n",
    "      downsample(256, 4, norm_type),  # output size: (batch size, 32, 32, 256)\n",
    "      downsample(512, 4, norm_type),  # output size: (batch size, 16, 16, 512)\n",
    "      downsample(512, 4, norm_type),  # output size: (batch size, 8, 8, 512)\n",
    "      downsample(512, 4, norm_type),  # output size: (batch size, 4, 4, 512)\n",
    "      downsample(512, 4, norm_type),  # output size: (batch size, 2, 2, 512)\n",
    "      downsample(512, 4, norm_type),  # output size: (batch size, 1, 1, 512)\n",
    "  ]\n",
    "\n",
    "  up_stack = [\n",
    "      upsample(512, 4, norm_type, apply_dropout=True),  # output size: (batch size, 2, 2, 1024)\n",
    "      upsample(512, 4, norm_type, apply_dropout=True),  # output size: (batch size, 4, 4, 1024)\n",
    "      upsample(512, 4, norm_type, apply_dropout=True),  # output size: (batch size, 8, 8, 1024)\n",
    "      upsample(512, 4, norm_type),  # output size: (batch size, 16, 16, 1024)\n",
    "      upsample(256, 4, norm_type),  # output size: (batch size, 32, 32, 512)\n",
    "      upsample(128, 4, norm_type),  # output size: (batch size, 64, 64, 256)\n",
    "      upsample(64, 4, norm_type),  # output size: (batch size, 128, 128, 128)\n",
    "  ]\n",
    "\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "  last = tf.keras.layers.Conv2DTranspose(\n",
    "      output_channels, 4, strides=2,\n",
    "      padding='same', kernel_initializer=initializer,\n",
    "      activation='tanh')  # output size: (batch size, 256, 256, 3)\n",
    "\n",
    "  concat = tf.keras.layers.Concatenate()\n",
    "\n",
    "  inputs = tf.keras.layers.Input(shape=[256, 256, 3])\n",
    "  x = inputs\n",
    "\n",
    "  # Downsampling through the model\n",
    "  skips = []\n",
    "\n",
    "  i=1\n",
    "  for down in down_stack:\n",
    "    x = down(x)\n",
    "    # Apply CBAM Attention after layer i\n",
    "    if i==6:\n",
    "        CA = ChannelAttention(x.shape[-1]) \n",
    "        # SA = SpatialAttention()\n",
    "        x = CA(x) * x  # channel attention \n",
    "        # x = SA(x) * x  # spatial attention \n",
    "    i+=1\n",
    "    skips.append(x)\n",
    "\n",
    "  skips = reversed(skips[:-1])\n",
    "\n",
    "  # Upsampling and establishing the skip connections\n",
    "  for up, skip in zip(up_stack, skips):\n",
    "    x = up(x)\n",
    "    x = concat([x, skip])\n",
    "        \n",
    "  x = last(x)\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(norm_type='batchnorm', target=True): # normalization type, whether target image is an input or not\n",
    "\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n",
    "  x = inp\n",
    "\n",
    "  if target:\n",
    "    tar = tf.keras.layers.Input(shape=[256, 256, 3], name='target_image')\n",
    "    x = tf.keras.layers.concatenate([inp, tar])  # output size: (batch size, 256, 256, channels*2)\n",
    "    \n",
    "  # apply CBAM attention in downsampling layers\n",
    "  x = downsample(64, 4, norm_type, False)(x)  # output size: (batch size, 128, 128, 64)\n",
    "  '''\n",
    "  CA = ChannelAttention(x.shape[-1])\n",
    "  SA = SpatialAttention()\n",
    "  x = CA(x) * x\n",
    "  x = SA(x) * x\n",
    "  '''\n",
    "  x = downsample(128, 4, norm_type)(x)  # output size: (batch size, 64, 64, 128)\n",
    "  '''\n",
    "  CA = ChannelAttention(x.shape[-1])\n",
    "  SA = SpatialAttention()\n",
    "  x = CA(x) * x\n",
    "  x = SA(x) * x\n",
    "  '''\n",
    "\n",
    "  x = downsample(256, 4, norm_type)(x)  # output size: (batch size, 32, 32, 256)\n",
    "  '''\n",
    "  CA = ChannelAttention(x.shape[-1])\n",
    "  SA = SpatialAttention()\n",
    "  x = CA(x) * x\n",
    "  x = SA(x) * x\n",
    "  '''\n",
    "\n",
    "  zero_pad1 = tf.keras.layers.ZeroPadding2D()(x)  # output size: (batch size, 34, 34, 256)\n",
    "  conv = tf.keras.layers.Conv2D(\n",
    "      512, 4, strides=1, kernel_initializer=initializer,\n",
    "      use_bias=False)(zero_pad1)  # output size: (batch size, 31, 31, 512)\n",
    "\n",
    "  if norm_type.lower() == 'batchnorm':\n",
    "    norm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "  elif norm_type.lower() == 'instancenorm':\n",
    "    norm1 = InstanceNormalization()(conv)\n",
    "\n",
    "  leaky_relu = tf.keras.layers.LeakyReLU()(norm1)\n",
    "  \n",
    "  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # output size: (batch size, 33, 33, 512)\n",
    "\n",
    "  last = tf.keras.layers.Conv2D(\n",
    "      1, 4, strides=1,\n",
    "      kernel_initializer=initializer)(zero_pad2)  # output size: (batch size, 30, 30, 1)\n",
    "\n",
    "  if target:\n",
    "    return tf.keras.Model(inputs=[inp, tar], outputs=last)\n",
    "  else:\n",
    "    return tf.keras.Model(inputs=inp, outputs=last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call GANs model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ju9Wyw87MRW"
   },
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "generator_g = unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "generator_f = unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "\n",
    "discriminator_x = discriminator(norm_type='instancenorm', target=False)\n",
    "discriminator_y = discriminator(norm_type='instancenorm', target=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the structure of generator G\n",
    "print(generator_g.summary())\n",
    "tf.keras.utils.plot_model(generator_g, show_shapes=True,dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the structure of generator F\n",
    "print(generator_f.summary())\n",
    "tf.keras.utils.plot_model(generator_f, show_shapes=True,dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the structure of discriminator X\n",
    "print(discriminator_x.summary())\n",
    "tf.keras.utils.plot_model(discriminator_x, show_shapes=True,dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the structure of discriminator Y\n",
    "print(discriminator_y.summary())\n",
    "tf.keras.utils.plot_model(discriminator_y, show_shapes=True,dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the performance of the generator and discriminator before training(Epoch=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wDaGZ3WpZUyw"
   },
   "outputs": [],
   "source": [
    "to_general_map = generator_g(sample_Gps_map)\n",
    "to_Gps_map = generator_f(sample_general_map)\n",
    "plt.figure(figsize=(8, 8))\n",
    "contrast = 8\n",
    "\n",
    "imgs = [sample_Gps_map, to_general_map, sample_general_map, to_Gps_map]\n",
    "title = ['Input satellite map', 'Predicted general layout map transferred by generator G', 'Input general layout map', 'Predicted satellite map transferred by generator F']\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "  plt.subplot(2, 2, i+1)\n",
    "  plt.title(title[i],fontsize=9)\n",
    "  if i % 2 == 0:\n",
    "    plt.imshow(imgs[i][0] * 0.5 + 0.5)\n",
    "  else:\n",
    "    plt.imshow(imgs[i][0] * 0.5 + 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O5MhJmxyZiy9"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.suptitle('Output feature maps from discriminator X and discriminator Y', fontsize=18)\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.title('Real satellite map→ Discriminator X')\n",
    "plt.imshow(discriminator_x(sample_Gps_map)[0, ..., -1], cmap='Spectral')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.title('Real general layout map→ Discriminator Y')\n",
    "plt.imshow(discriminator_y(sample_general_map)[0, ..., -1], cmap='Spectral')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FMYgY_mPfTi"
   },
   "source": [
    "## Define the loss function and set optimizer and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cyhxTuvJyIHV"
   },
   "outputs": [],
   "source": [
    "LAMBDA = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q1Xbz5OaLj5C"
   },
   "outputs": [],
   "source": [
    "loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkMNfBWlT-PV"
   },
   "outputs": [],
   "source": [
    "# \n",
    "def discriminator_loss(real, generated):\n",
    "  real_loss = loss_obj(tf.ones_like(real), real)\n",
    "\n",
    "  generated_loss = loss_obj(tf.zeros_like(generated), generated)\n",
    "\n",
    "  total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "  return total_disc_loss * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "90BIcCKcDMxz"
   },
   "outputs": [],
   "source": [
    "def generator_loss(generated):\n",
    "  return loss_obj(tf.ones_like(generated), generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMpVGj_sW6Vo"
   },
   "outputs": [],
   "source": [
    "def calc_cycle_loss(real_image, cycled_image):\n",
    "  loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "  \n",
    "  return LAMBDA * loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05ywEH680Aud"
   },
   "outputs": [],
   "source": [
    "def identity_loss(real_image, same_image):\n",
    "  loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "  return LAMBDA * 0.5 * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWCn_PVdEJZ7"
   },
   "outputs": [],
   "source": [
    "# define optimizer and learning rate\n",
    "generator_g_optimizer = tf.keras.optimizers.Adam(1e-4,0.9)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(1e-4,0.9)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(1e-4,0.9)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(1e-4,0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aKUZnDiqQrAh"
   },
   "source": [
    "## Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WJnftd5sQsv6"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           generator_f=generator_f,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           generator_f_optimizer=generator_f_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rw1fkAczTQYh"
   },
   "source": [
    "## Define the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NS2GWywBbAWo"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RmdVsmvhPxyy"
   },
   "outputs": [],
   "source": [
    "def generate_images_g(model, test_input): # model, input data after normalization\n",
    "  prediction = model(test_input)\n",
    "    \n",
    "  plt.figure(figsize=(12, 12))\n",
    "\n",
    "  display_list = [test_input[0], prediction[0]]\n",
    "  title = ['Input satellite map', 'Predicted general layout map transferred by generator G']\n",
    "\n",
    "  for i in range(2):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "  for i in range(120):\n",
    "     print('=',end='')\n",
    "  return tf.reshape(prediction,(-1,256,256,3)) # return the normalization image data\n",
    "\n",
    "def generate_images_f(model, test_input): # model, input data after normalization\n",
    "  prediction = model(test_input)\n",
    "    \n",
    "  plt.figure(figsize=(12, 12))\n",
    "\n",
    "  display_list = [test_input[0], prediction[0]]\n",
    "  title = ['Input general layout map', 'Predicted satellite map transferred by generator F']\n",
    "\n",
    "  for i in range(2):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "  \n",
    "  for i in range(80):\n",
    "    print('>',end='')\n",
    "  return tf.reshape(prediction,(-1,256,256,3)) # return the normalization image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KBKUV2sKXDbY"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_x, real_y):\n",
    "  with tf.GradientTape(persistent=True) as tape:\n",
    "    \n",
    "    fake_y = generator_g(real_x, training=True)\n",
    "    cycled_x = generator_f(fake_y, training=True)\n",
    "\n",
    "    fake_x = generator_f(real_y, training=True)\n",
    "    cycled_y = generator_g(fake_x, training=True)\n",
    "\n",
    "    same_x = generator_f(real_x, training=True)\n",
    "    same_y = generator_g(real_y, training=True)\n",
    "\n",
    "    disc_real_x = discriminator_x(real_x, training=True)\n",
    "    disc_real_y = discriminator_y(real_y, training=True)\n",
    "\n",
    "    disc_fake_x = discriminator_x(fake_x, training=True)\n",
    "    disc_fake_y = discriminator_y(fake_y, training=True)\n",
    "\n",
    "    gen_g_loss = generator_loss(disc_fake_y)\n",
    "    gen_f_loss = generator_loss(disc_fake_x)\n",
    "    \n",
    "    total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + calc_cycle_loss(real_y, cycled_y)\n",
    "    \n",
    "    # total generator loss = adversarial loss + cycle loss\n",
    "    total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y, same_y)\n",
    "    total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x, same_x)\n",
    "\n",
    "    disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
    "    disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n",
    "  \n",
    "  # Calculate the gradients for generator and discriminator\n",
    "  generator_g_gradients = tape.gradient(total_gen_g_loss, generator_g.trainable_variables)\n",
    "  generator_f_gradients = tape.gradient(total_gen_f_loss, generator_f.trainable_variables)\n",
    "  \n",
    "  discriminator_x_gradients = tape.gradient(disc_x_loss, discriminator_x.trainable_variables)\n",
    "  discriminator_y_gradients = tape.gradient(disc_y_loss, discriminator_y.trainable_variables)\n",
    "  \n",
    "  # apply the gradients to the optimizer\n",
    "  generator_g_optimizer.apply_gradients(zip(generator_g_gradients, generator_g.trainable_variables))\n",
    "  generator_f_optimizer.apply_gradients(zip(generator_f_gradients, generator_f.trainable_variables))\n",
    "  discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients, discriminator_x.trainable_variables))\n",
    "  discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients, discriminator_y.trainable_variables))\n",
    "  \n",
    "  return total_gen_g_loss,total_gen_f_loss,disc_x_loss,disc_y_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the function used to calculate FID score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import cov\n",
    "from numpy import trace\n",
    "from numpy import iscomplexobj\n",
    "from numpy import asarray\n",
    "from numpy.random import randint\n",
    "from scipy.linalg import sqrtm\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from skimage.transform import resize\n",
    " \n",
    "# scale an array of images to a new size\n",
    "def scale_images(images, new_shape):\n",
    "    images_list = list()\n",
    "    for image in images:\n",
    "        # resize with nearest neighbor interpolation\n",
    "        new_image = resize(image, new_shape, 0)\n",
    "        # store\n",
    "        images_list.append(new_image)\n",
    "    return asarray(images_list)\n",
    " \n",
    "# calculate frechet inception distance\n",
    "def calculate_fid(model, images1, images2):\n",
    "\n",
    "    images1 = scale_images(images1, (299,299,3))\n",
    "    images2 = scale_images(images2, (299,299,3))\n",
    "\n",
    "    images1 = preprocess_input(images1)\n",
    "    images2 = preprocess_input(images2)    \n",
    "    \n",
    "    act1 = model.predict(images1)\n",
    "    act2 = model.predict(images2)\n",
    "    mu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
    "    mu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
    "    ssdiff = np.sum((mu1 - mu2)**2.0)\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "    if iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    fid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid\n",
    " \n",
    "# get the two image data sets used to calculate the FID score\n",
    "def get_scored_datasets(input_dataset,model,real_dataset,test_number): \n",
    "\n",
    "    input_image_set=np.array([])\n",
    "    fake_image_set=np.array([])\n",
    "    real_image_set=np.array([])\n",
    "    \n",
    "    for inp in input_dataset.take(test_number):\n",
    "        input_image=tf.reshape(inp,(-1,256,256,3))    \n",
    "        fake_image=model(input_image).numpy()    \n",
    "        input_image=(input_image.numpy()).astype(np.float32)\n",
    "        input_image_set=np.append(input_image_set,input_image)        \n",
    "        fake_image_set=(np.append(fake_image_set,fake_image)).astype(np.float32)        \n",
    "    input_image_set=np.reshape(input_image_set,[-1,256,256,3])    \n",
    "    input_image_set=tf.convert_to_tensor(input_image_set)\n",
    "    fake_image_set=np.reshape(fake_image_set,[-1,256,256,3])\n",
    "    fake_image_set=tf.convert_to_tensor(fake_image_set)\n",
    "\n",
    "    for inp in real_dataset.take(test_number):\n",
    "        real_image=tf.reshape(inp,(-1,256,256,3))    \n",
    "        real_image=(real_image.numpy()).astype(np.float32)\n",
    "        real_image_set=(np.append(real_image_set,real_image)).astype(np.float32)         \n",
    "    real_image_set=np.reshape(real_image_set,[-1,256,256,3])    \n",
    "    real_image_set=tf.convert_to_tensor(real_image_set)\n",
    "    return input_image_set,fake_image_set,real_image_set\n",
    "\n",
    "model_FID = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gen_g_loss_plot,gen_f_loss_plot,disc_x_loss_plot,disc_y_loss_plot=np.array([]),np.array([]),np.array([]),np.array([])\n",
    "gen_g_trainingset_fidplot,gen_f_trainingset_fidplot,gen_g_testset_fidplot,gen_f_testset_fidplot=np.array([]),np.array([]),np.array([]),np.array([])\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  n = 0\n",
    "  gen_g_loss_list,gen_f_loss_list,disc_x_loss_list,disc_y_loss_list=np.array([]),np.array([]),np.array([]),np.array([])\n",
    "  for image_x, image_y in tf.data.Dataset.zip((train_Gps_maps, train_general_maps)):\n",
    "    gen_g_loss_step, gen_f_loss_step, disc_x_loss_step, disc_y_loss_step = train_step(image_x, image_y)\n",
    "    gen_g_loss_list=np.append(gen_g_loss_list,gen_g_loss_step.numpy())\n",
    "    gen_f_loss_list=np.append(gen_f_loss_list,gen_f_loss_step.numpy())\n",
    "    disc_x_loss_list=np.append(disc_x_loss_list,disc_x_loss_step.numpy())\n",
    "    disc_y_loss_list=np.append(disc_y_loss_list,disc_y_loss_step.numpy())                                                                                                                        \n",
    "    if n % 10 == 0:\n",
    "      print ('.', end='')\n",
    "    n+=1\n",
    "  gen_g_loss_plot=np.append(gen_g_loss_plot,gen_g_loss_list.mean())\n",
    "  gen_f_loss_plot=np.append(gen_f_loss_plot,gen_f_loss_list.mean())\n",
    "  disc_x_loss_plot=np.append(disc_x_loss_plot,disc_x_loss_list.mean())\n",
    "  disc_y_loss_plot=np.append(disc_y_loss_plot,disc_y_loss_list.mean())\n",
    "  \n",
    "  input_image_set,fake_image_set,real_image_set=get_scored_datasets(train_Gps_maps,generator_g,train_general_maps,100)\n",
    "  fid = calculate_fid(model_FID, real_image_set, fake_image_set)\n",
    "  gen_g_trainingset_fidplot=np.append(gen_g_trainingset_fidplot,fid)                     \n",
    "\n",
    "  input_image_set,fake_image_set,real_image_set=get_scored_datasets(train_general_maps,generator_f,train_Gps_maps,100)\n",
    "  fid = calculate_fid(model_FID, real_image_set, fake_image_set)\n",
    "  gen_f_trainingset_fidplot=np.append(gen_f_trainingset_fidplot,fid) \n",
    "\n",
    "  input_image_set,fake_image_set,real_image_set=get_scored_datasets(test_Gps_maps,generator_g,test_general_maps,100)\n",
    "  fid = calculate_fid(model_FID, real_image_set, fake_image_set)\n",
    "  gen_g_testset_fidplot=np.append(gen_g_testset_fidplot,fid) \n",
    "\n",
    "  input_image_set,fake_image_set,real_image_set=get_scored_datasets(test_general_maps,generator_f,test_Gps_maps,100)\n",
    "  fid = calculate_fid(model_FID, real_image_set, fake_image_set)\n",
    "  gen_f_testset_fidplot=np.append(gen_f_testset_fidplot,fid) \n",
    "                           \n",
    "  if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "    print('\\nTest on input satellite map from training set:')\n",
    "    fake_image_g1=generate_images_g(generator_g,tf.reshape(sample_Gps_map,(-1,256,256,3)))\n",
    "    fake_image_f1=generate_images_f(generator_f,tf.reshape(fake_image_g1,(-1,256,256,3)))\n",
    "  \n",
    "    print('\\nTest on input general layout map from training set:')  \n",
    "    fake_image_f2=generate_images_f(generator_f,tf.reshape(sample_general_map,(-1,256,256,3)))\n",
    "    fake_image_g2=generate_images_g(generator_g,tf.reshape(fake_image_f2,(-1,256,256,3)))\n",
    "   \n",
    "  if (epoch + 1) % EPOCHS == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,ckpt_save_path))\n",
    "\n",
    "\n",
    "  print ('\\n Epoch-{}:Generator G Loss={}, Generator F Loss={}, Discriminator X Loss={}, Discriminator Y Loss={}.'.format(epoch + 1,gen_g_loss_plot[-1],gen_f_loss_plot[-1],disc_x_loss_plot[-1],disc_y_loss_plot[-1]))\n",
    "  print ('\\n Epoch-{}:Generator G(training set)-FID Score={}, Generator F(training set)-FID Score={}, Generator G(test set)-FID Score={},Generator F(test set)-FID Score={}.'.format(epoch + 1,gen_g_trainingset_fidplot[-1],gen_f_trainingset_fidplot[-1],gen_g_testset_fidplot[-1],gen_f_testset_fidplot[-1]))\n",
    "  print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 800\n",
    "def training_visualisation (gen_g_loss_plot, gen_f_loss_plot, disc_x_loss_plot, disc_y_loss_plot, gen_g_trainingset_fidplot, gen_f_trainingset_fidplot, gen_g_testset_fidplot, gen_f_testset_fidplot, num_epochs=EPOCHS):\n",
    "    plt.figure(figsize=(12,7))\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.title(\"Generator's Loss with Epochs\")\n",
    "    plt.xlabel(\"Training Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(range(1,num_epochs+1), gen_g_loss_plot , ls=\"-\", color=\"#0072BD\", lw=2, label=\"Generator G\")\n",
    "    plt.plot(range(1,num_epochs+1), gen_f_loss_plot , ls=\"-.\", color=\"#D95319\", lw=2, label=\"Generator F\")\n",
    "    plt.legend(frameon=True)\n",
    "\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.title(\"Discriminator's Loss with Epochs\")\n",
    "    plt.xlabel(\"Training Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(range(1,num_epochs+1), disc_x_loss_plot, ls=\"-\", color=\"#EDB120\", lw=2, label=\"Discriminator X\")\n",
    "    plt.plot(range(1,num_epochs+1), disc_y_loss_plot, ls=\"-.\", color=\"#7E2F8E\", lw=2, label=\"Discriminator Y\")\n",
    "    plt.legend(frameon=True)\n",
    "\n",
    "\n",
    "    \n",
    "    plt.subplot(2,2,3)\n",
    "    plt.title(\"General Layout Map Generation Mission's FID Score with Epochs\")\n",
    "    plt.xlabel(\"Training Epochs\")\n",
    "    plt.ylabel(\"FID Score\")\n",
    "    plt.plot(range(1,num_epochs+1), gen_g_trainingset_fidplot, ls=\"-\", color=\"#77AC30\", lw=2, label=\"Generator G on training set\")\n",
    "    plt.plot(range(1,num_epochs+1), gen_g_testset_fidplot, ls=\"-.\", color=\"#4DBEEE\", lw=2, label=\"Generator G on test set\")\n",
    "    plt.legend(frameon=True)\n",
    "\n",
    "    \n",
    "    plt.subplot(2,2,4)\n",
    "    plt.title(\"Satellite Map Generation Mission's FID Score with Epochs\")\n",
    "    plt.xlabel(\"Training Epochs\")\n",
    "    plt.ylabel(\"FID Score\")\n",
    "    plt.plot(range(1,num_epochs+1), gen_f_trainingset_fidplot, ls=\"-\", color=\"#A2142F\", lw=2, label=\"Generator F on training set\")\n",
    "    plt.plot(range(1,num_epochs+1), gen_f_testset_fidplot, ls=\"-.\", color=\"#143CA2\", lw=2, label=\"Generator F on test set\")\n",
    "    plt.legend(frameon=True)\n",
    "    plt.tight_layout()   \n",
    "    \n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "training_visualisation(gen_g_loss_plot, gen_f_loss_plot, disc_x_loss_plot, disc_y_loss_plot, gen_g_trainingset_fidplot, gen_f_trainingset_fidplot, gen_g_testset_fidplot, gen_f_testset_fidplot, num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1RGysMU_BZhx"
   },
   "source": [
    "# After training, use the test set to test the generation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KUgSnmy2nqSP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Restore the latest checkpoint\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')\n",
    "\n",
    "test_number=15\n",
    "i=1    \n",
    "\n",
    "for inp in test_Gps_maps.take(test_number): \n",
    "    print('\\nTest set-Input satellite map-'+str(i))\n",
    "    fake_image_g1=generate_images_g(generator_g,tf.reshape(inp,(-1,256,256,3)))\n",
    "    fake_image_f1=generate_images_f(generator_f,tf.reshape(fake_image_g1,(-1,256,256,3)))\n",
    "    i+=1\n",
    "    \n",
    "i=1    \n",
    "for inp in test_general_maps.take(test_number): \n",
    "    print('\\nTest set-Input general layout map-'+str(i))  \n",
    "    fake_image_f2=generate_images_f(generator_f,tf.reshape(inp,(-1,256,256,3)))\n",
    "    fake_image_g2=generate_images_g(generator_g,tf.reshape(fake_image_f2,(-1,256,256,3)))\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After training, test the performance of the generator and discriminator on the sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_general_map = generator_g(sample_Gps_map)\n",
    "to_Gps_map = generator_f(sample_general_map)\n",
    "plt.figure(figsize=(8, 8))\n",
    "contrast = 8\n",
    "\n",
    "imgs = [sample_Gps_map, to_general_map, sample_general_map, to_Gps_map]\n",
    "title = ['Input real satellite map', 'Predicted general layout map transferred by generator G', 'Input real general layout map', 'Predicted satellite map transferred by generator F']\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "  plt.subplot(2, 2, i+1)\n",
    "  plt.title(title[i],fontsize=9)\n",
    "  if i % 2 == 0:\n",
    "    plt.imshow(imgs[i][0] * 0.5 + 0.5)\n",
    "  else:\n",
    "    plt.imshow(imgs[i][0] * 0.5 + 0.5)\n",
    "    #plt.imshow(imgs[i][0] * 0.5 * contrast + 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.suptitle('Output feature maps from discriminator X and discriminator Y', fontsize=18)\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.title('Real satellite map→ Discriminator X')\n",
    "plt.imshow(discriminator_x(sample_Gps_map)[0, ..., -1], cmap='Spectral')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.title('G:Fake general layout map→ Discriminator Y')\n",
    "plt.imshow(discriminator_y(to_general_map)[0, ..., -1], cmap='Spectral')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.title('Real general layout map→ Discriminator Y')\n",
    "plt.imshow(discriminator_y(sample_general_map)[0, ..., -1], cmap='Spectral')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.title('F:Fake satellite map→ Discriminator X')\n",
    "plt.imshow(discriminator_x(to_Gps_map)[0, ..., -1], cmap='Spectral')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally test the generation performance on the map of Leeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "def test_leeds_image(input_image_dir,generate_images_g_or_f,generator_g_or_f,real_image_dir):\n",
    "    input_image = tf.io.read_file(input_image_dir, 'r')\n",
    "    input_image = tf.image.decode_jpeg(input_image)\n",
    "    input_image = tf.image.resize(input_image, [256, 256],method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    input_image = normalize(input_image)\n",
    "    input_image = tf.reshape(input_image,(-1,256,256,3))\n",
    "    fake_image=generate_images_g_or_f(generator_g_or_f,input_image)\n",
    "    real_image = tf.io.read_file(real_image_dir, 'r')\n",
    "    real_image = tf.image.decode_jpeg(real_image)\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(real_image)\n",
    "    plt.title('Google map-version: 10.49.2)')\n",
    "    real_image = tf.image.resize(real_image, [256, 256],method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    real_image = normalize(real_image)\n",
    "    real_image = tf.reshape(real_image,(-1,256,256,3))   \n",
    "    return input_image,fake_image,real_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_image,fake_image,real_image = test_leeds_image('..\\..\\dataset\\leeds\\\\Gps_roundhay.jpg',generate_images_g,generator_g,'..\\..\\dataset\\leeds\\Layout_roundhay.jpg')\n",
    "\n",
    "input_image,fake_image,real_image = test_leeds_image('..\\..\\dataset\\leeds\\Gps_woodhouse.jpg',generate_images_g,generator_g,'..\\..\\dataset\\leeds\\Layout_woodhouse.jpg')\n",
    "\n",
    "input_image,fake_image,real_image = test_leeds_image('..\\..\\dataset\\leeds\\Gps_airport.jpg',generate_images_g,generator_g,'..\\..\\dataset\\leeds\\Layout_airport.jpg')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cyclegan.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
